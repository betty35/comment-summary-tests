{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/betty35/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0412 20:19:48.297299 140570116118272 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time, os, shutil\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np  \n",
    "from sklearn.cluster import KMeans  \n",
    "from sklearn.cluster import DBSCAN\n",
    "from nltk.parse import CoreNLPParser\n",
    "\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'output/sub-set/'\n",
    "file_name = 'Fire HD'+'.csv'\n",
    "df = pd.read_csv(data_source+file_name, sep=\"\\t\", error_bad_lines=False)\n",
    "reviews = pd.DataFrame(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['POS'] = reviews.text.apply(lambda x: pos_tagger.tag(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(r'/mnt/doc/School/USYD/Capstone/workspace/data_testing/output/sub-set/fireHD-tag.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('I', 'PRP'),\n",
       "  ('find', 'VBP'),\n",
       "  ('that', 'DT'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('not', 'RB'),\n",
       "  ('as', 'RB'),\n",
       "  ('easy', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('use', 'VB'),\n",
       "  ('as', 'IN'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('regular', 'JJ'),\n",
       "  ('Kindle', 'NNP'),\n",
       "  ('Fire', 'NNP')],\n",
       " [('When', 'WRB'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('reading', 'VBG'),\n",
       "  ('the', 'DT'),\n",
       "  ('kindle', 'NN'),\n",
       "  ('it', 'PRP'),\n",
       "  ('freezes', 'VBZ'),\n",
       "  ('up', 'RP'),\n",
       "  ('-LRB-', '-LRB-'),\n",
       "  ('because', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('hold', 'VBP'),\n",
       "  ('it', 'PRP'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('side', 'NN'),\n",
       "  ('-RRB-', '-RRB-')],\n",
       " [('Also', 'RB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('have', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('get', 'VB'),\n",
       "  ('out', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('it', 'PRP'),\n",
       "  ('to', 'TO'),\n",
       "  ('brighten', 'VB'),\n",
       "  ('or', 'CC'),\n",
       "  ('darken', 'VB'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('text', 'NN'),\n",
       "  ('that', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('reading', 'VBG')],\n",
       " [('Lastly', 'RB'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('advertisements', 'NNS'),\n",
       "  ('that', 'WDT'),\n",
       "  ('come', 'VBP'),\n",
       "  ('up', 'RP'),\n",
       "  ('every', 'DT'),\n",
       "  ('time', 'NN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('turn', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('HD', 'NN'),\n",
       "  ('Kindle', 'NNP'),\n",
       "  ('Fire', 'NNP'),\n",
       "  ('on', 'IN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('annoying', 'VBG')],\n",
       " [('Convenient', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('use', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('library', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('download', 'VB'),\n",
       "  ('books', 'NNS')],\n",
       " [('Should', 'MD'),\n",
       "  ('have', 'VB'),\n",
       "  ('done', 'VBN'),\n",
       "  ('this', 'DT'),\n",
       "  ('a', 'DT'),\n",
       "  ('long', 'JJ'),\n",
       "  ('time', 'NN'),\n",
       "  ('ago', 'IN')],\n",
       " [('The', 'DT'),\n",
       "  ('video', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('best', 'JJS')],\n",
       " [('I', 'PRP'),\n",
       "  ('do', 'VBP'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('bother', 'VB'),\n",
       "  ('watching', 'VBG'),\n",
       "  ('the', 'DT'),\n",
       "  ('news', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('television', 'NN'),\n",
       "  ('anymore', 'RB'),\n",
       "  (',', ','),\n",
       "  ('I', 'PRP'),\n",
       "  ('go', 'VBP'),\n",
       "  ('straight', 'RB'),\n",
       "  ('to', 'TO'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('Kindle', 'NNP'),\n",
       "  ('Fire', 'NNP')],\n",
       " [('Could', 'MD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('be', 'VB'),\n",
       "  ('happier', 'JJR'),\n",
       "  ('with', 'IN'),\n",
       "  ('this', 'DT')],\n",
       " [('Good', 'JJ'),\n",
       "  ('reading', 'NN'),\n",
       "  ('device', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('easy', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('use', 'VB')]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['POS'][0:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMainWords(pos):\n",
    "    result = '';\n",
    "    for x in pos:\n",
    "        if x[1][0:2] in ['NN','VB']:\n",
    "            result= result+x[0]+' '\n",
    "    if len(result)>0:\n",
    "        result= result[0:len(result)-1]\n",
    "    return result\n",
    "\n",
    "reviews['main'] = list(map(getMainWords,reviews['POS']))\n",
    "reviews = reviews.loc[reviews['main'].apply(len)>0,['text','main']] #filtering out sentences without any nouns or verbs\n",
    "\n",
    "reviews = reviews.reset_index(drop=True)# reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If load data with 'text' and 'main'\n",
    "data_source = 'output/sub-set/'\n",
    "file_name = 'fireHD-tag'+'.csv'\n",
    "reviews = pd.read_csv(data_source+file_name, sep=\"\\t\", error_bad_lines=False).loc[:,['text','main']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/betty35/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 20:21:22.740859 140570116118272 deprecation.py:323] From /home/betty35/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Load google Universal Sentence Encoder\n",
    "module_dir =\"downloads/encoder-DNA\" #\"downloads/encoder\"\n",
    "embed = hub.Module(module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 20:21:53.503647 140570116118272 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 20:21:58.211255 140570116118272 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time1: 5.509376764297485  time2: 3.5216400623321533\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    start_time=time.time()\n",
    "    reviews['sentence_embedding'] = pd.Series(list(session.run(embed(list(reviews['text'])))))\n",
    "    end_time1=time.time()\n",
    "    reviews['words_embedding'] = pd.Series(list(session.run(embed(list(reviews['main'])))))\n",
    "    end_time2=time.time()\n",
    "    print('time1:',(end_time1-start_time),' time2:',(end_time2-end_time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub=reviews.loc[:,['text','main']]\n",
    "#sub.to_csv(r'/mnt/doc/School/USYD/Capstone/workspace/data_testing/output/sub-set/fireHD-tag.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing datasets\n",
    "X1 = np.array(reviews['sentence_embedding'].tolist())\n",
    "X2 = np.array(reviews['words_embedding'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for clustering sentence embeddings: 10.899672746658325\n",
      "time for clustering words embeddings: 10.898835897445679\n"
     ]
    }
   ],
   "source": [
    "# Clustering\n",
    "time1 = time.time()\n",
    "db_s = DBSCAN(eps=0.4).fit(X1)\n",
    "print('time for clustering sentence embeddings:', (time.time()-time1))\n",
    "time1 = time.time()\n",
    "db_w = DBSCAN(eps=0.4).fit(X2)\n",
    "print('time for clustering words embeddings:',(time.time()-time1))\n",
    "# Get labels\n",
    "labels_s = db_s.labels_.tolist()\n",
    "labels_w = db_w.labels_.tolist()\n",
    "reviews['label_db_sentence'] = labels_s\n",
    "reviews['label_db_word'] = labels_w\n",
    "n_sentence= len(set(labels_s)) - (1 if -1 in labels_s else 0)\n",
    "n_words=len(set(labels_w)) - (1 if -1 in labels_w else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences: 3355\n",
      "clusters for sentences: 2 noise: 854\n",
      "clusters for words: 15 noise: 1041\n"
     ]
    }
   ],
   "source": [
    "print('total sentences:',len(list(labels_s)))\n",
    "print('clusters for sentences:',n_sentence, 'noise:',list(labels_s).count(-1))\n",
    "print('clusters for words:',n_words, 'noise:',list(labels_w).count(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_dir(product_name, method, params):\n",
    "    dir_pre = '/home/betty35/桌面/Capstone/workspace/data_testing/output/'\n",
    "    dir_ = dir_pre+product_name+'/'+method+'/'+params+'/'\n",
    "    return dir_\n",
    "\n",
    "\n",
    "def make_dir(dir_):\n",
    "    if not os.path.exists(dir_):\n",
    "        try:\n",
    "            os.makedirs(dir_)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "def clean_dir(dir_):\n",
    "    for file_ in os.listdir(dir_):\n",
    "        file_dir = os.path.join(dir_, file_)\n",
    "        try:\n",
    "            if os.path.isfile(file_dir):\n",
    "                os.unlink(file_dir)\n",
    "            elif os.path.isdir(file_dir): shutil.rmtree(file_dir)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def make_or_clean_dir(dir_):\n",
    "    make_dir(dir_)\n",
    "    clean_dir(dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_title='Fire HD'\n",
    "params='0.8'\n",
    "dir1 = save_results_dir(product_title,'dbscan',params+'/sentence')\n",
    "make_or_clean_dir(dir1)\n",
    "for i in range(0,n_sentence):    \n",
    "    temp = reviews.loc[reviews['label_db_sentence']==i,['text']]\n",
    "    file_name = str(i)+'.txt'\n",
    "    np.savetxt(r''+dir1+file_name, temp.values, fmt='%s')\n",
    "\n",
    "noise_s = temp = reviews.loc[reviews['label_db_sentence']==-1,['text']] \n",
    "np.savetxt(r''+dir1+'noise.txt', temp.values, fmt='%s')\n",
    "\n",
    "dir1 = save_results_dir(product_title,'dbscan',params+'/word')\n",
    "make_or_clean_dir(dir1)\n",
    "for i in range(0,n_words):\n",
    "    temp = reviews.loc[reviews['label_db_word']==i,['text']]\n",
    "    file_name = str(i)+'.txt'\n",
    "    np.savetxt(r''+dir1+file_name, temp.values, fmt='%s')\n",
    "noise_s = temp = reviews.loc[reviews['label_db_word']==-1,['text']] \n",
    "np.savetxt(r''+dir1+'noise.txt', temp.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
