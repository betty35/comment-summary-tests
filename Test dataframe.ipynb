{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page for trying out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0502 15:54:05.637127  5876 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time, os, shutil\n",
    "import nltk\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np  \n",
    "from sklearn.cluster import KMeans  \n",
    "from sklearn.cluster import DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 42306: expected 15 fields, saw 22\\nSkipping line 61136: expected 15 fields, saw 22\\nSkipping line 64592: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 73268: expected 15 fields, saw 22\\nSkipping line 80720: expected 15 fields, saw 22\\nSkipping line 120624: expected 15 fields, saw 22\\nSkipping line 121776: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 154351: expected 15 fields, saw 22\\nSkipping line 155937: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 203615: expected 15 fields, saw 22\\nSkipping line 208061: expected 15 fields, saw 22\\nSkipping line 212638: expected 15 fields, saw 22\\nSkipping line 219390: expected 15 fields, saw 22\\nSkipping line 235195: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 284570: expected 15 fields, saw 22\\nSkipping line 297246: expected 15 fields, saw 22\\nSkipping line 326901: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 344609: expected 15 fields, saw 22\\nSkipping line 347706: expected 15 fields, saw 22\\nSkipping line 348978: expected 15 fields, saw 22\\nSkipping line 349036: expected 15 fields, saw 22\\nSkipping line 377234: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 402960: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 525406: expected 15 fields, saw 22\\nSkipping line 535885: expected 15 fields, saw 22\\nSkipping line 558276: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 604498: expected 15 fields, saw 22\\nSkipping line 652606: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 656793: expected 15 fields, saw 22\\nSkipping line 686204: expected 15 fields, saw 22\\nSkipping line 709412: expected 15 fields, saw 22\\nSkipping line 712042: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 733264: expected 15 fields, saw 22\\nSkipping line 770653: expected 15 fields, saw 22\\nSkipping line 781551: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 791527: expected 15 fields, saw 22\\nSkipping line 798042: expected 15 fields, saw 22\\nSkipping line 807385: expected 15 fields, saw 22\\nSkipping line 810615: expected 15 fields, saw 22\\nSkipping line 844532: expected 15 fields, saw 22\\nSkipping line 846206: expected 15 fields, saw 22\\nSkipping line 847697: expected 15 fields, saw 22\\nSkipping line 848202: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 852145: expected 15 fields, saw 22\\nSkipping line 852660: expected 15 fields, saw 22\\nSkipping line 856127: expected 15 fields, saw 22\\nSkipping line 865441: expected 15 fields, saw 22\\nSkipping line 887198: expected 15 fields, saw 22\\nSkipping line 894406: expected 15 fields, saw 22\\nSkipping line 916051: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 993142: expected 15 fields, saw 22\\nSkipping line 1011929: expected 15 fields, saw 22\\nSkipping line 1034946: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1111605: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1166130: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1180823: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1286843: expected 15 fields, saw 22\\nSkipping line 1290568: expected 15 fields, saw 22\\nSkipping line 1292107: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1310971: expected 15 fields, saw 22\\nSkipping line 1319111: expected 15 fields, saw 22\\nSkipping line 1352063: expected 15 fields, saw 22\\nSkipping line 1355003: expected 15 fields, saw 22\\nSkipping line 1357701: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1400165: expected 15 fields, saw 22\\nSkipping line 1402478: expected 15 fields, saw 22\\nSkipping line 1409210: expected 15 fields, saw 22\\nSkipping line 1436022: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1448705: expected 15 fields, saw 22\\nSkipping line 1451228: expected 15 fields, saw 22\\nSkipping line 1461128: expected 15 fields, saw 22\\nSkipping line 1464998: expected 15 fields, saw 22\\nSkipping line 1466419: expected 15 fields, saw 22\\nSkipping line 1494640: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1554738: expected 15 fields, saw 22\\nSkipping line 1557296: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1583737: expected 15 fields, saw 22\\nSkipping line 1584239: expected 15 fields, saw 22\\nSkipping line 1590283: expected 15 fields, saw 22\\nSkipping line 1634095: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1649977: expected 15 fields, saw 22\\nSkipping line 1658352: expected 15 fields, saw 22\\nSkipping line 1674985: expected 15 fields, saw 22\\nSkipping line 1686716: expected 15 fields, saw 22\\nSkipping line 1697922: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1713285: expected 15 fields, saw 22\\nSkipping line 1734676: expected 15 fields, saw 22\\nSkipping line 1738399: expected 15 fields, saw 22\\nSkipping line 1741814: expected 15 fields, saw 22\\nSkipping line 1747515: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1787608: expected 15 fields, saw 22\\nSkipping line 1794400: expected 15 fields, saw 22\\nSkipping line 1807723: expected 15 fields, saw 22\\nSkipping line 1809920: expected 15 fields, saw 22\\nSkipping line 1820224: expected 15 fields, saw 22\\nSkipping line 1830087: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1914778: expected 15 fields, saw 22\\nSkipping line 1916219: expected 15 fields, saw 22\\nSkipping line 1926957: expected 15 fields, saw 22\\nSkipping line 1935726: expected 15 fields, saw 22\\nSkipping line 1949568: expected 15 fields, saw 22\\nSkipping line 1952979: expected 15 fields, saw 22\\nSkipping line 1954367: expected 15 fields, saw 22\\nSkipping line 1963708: expected 15 fields, saw 22\\nSkipping line 1965034: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1968879: expected 15 fields, saw 22\\nSkipping line 1987791: expected 15 fields, saw 22\\nSkipping line 2002178: expected 15 fields, saw 22\\nSkipping line 2007411: expected 15 fields, saw 22\\nSkipping line 2011694: expected 15 fields, saw 22\\nSkipping line 2016595: expected 15 fields, saw 22\\nSkipping line 2021800: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2178514: expected 15 fields, saw 22\\nSkipping line 2210320: expected 15 fields, saw 22\\nSkipping line 2212163: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2254350: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2296430: expected 15 fields, saw 22\\nSkipping line 2301015: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2369550: expected 15 fields, saw 22\\nSkipping line 2372919: expected 15 fields, saw 22\\nSkipping line 2373511: expected 15 fields, saw 22\\nSkipping line 2374204: expected 15 fields, saw 22\\nSkipping line 2378031: expected 15 fields, saw 22\\nSkipping line 2387181: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2432561: expected 15 fields, saw 22\\nSkipping line 2445761: expected 15 fields, saw 22\\nSkipping line 2459959: expected 15 fields, saw 22\\nSkipping line 2470385: expected 15 fields, saw 22\\nSkipping line 2474790: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2500009: expected 15 fields, saw 22\\nSkipping line 2522971: expected 15 fields, saw 22\\nSkipping line 2523952: expected 15 fields, saw 22\\nSkipping line 2537329: expected 15 fields, saw 22\\nSkipping line 2537962: expected 15 fields, saw 22\\nSkipping line 2546150: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2611460: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2679125: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2687826: expected 15 fields, saw 22\\nSkipping line 2711545: expected 15 fields, saw 22\\nSkipping line 2737091: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2764733: expected 15 fields, saw 22\\nSkipping line 2764771: expected 15 fields, saw 22\\nSkipping line 2766946: expected 15 fields, saw 22\\nSkipping line 2795416: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2822371: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2884239: expected 15 fields, saw 22\\nSkipping line 2948495: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2978559: expected 15 fields, saw 22\\nSkipping line 2998169: expected 15 fields, saw 22\\nSkipping line 3003265: expected 15 fields, saw 22\\nSkipping line 3003662: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3035912: expected 15 fields, saw 22\\nSkipping line 3054746: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3301954: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3563377: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3952435: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4144878: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4208693: expected 15 fields, saw 22\\nSkipping line 4217407: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 4382584: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4794835: expected 15 fields, saw 22\\nSkipping line 4840336: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 5002329: expected 15 fields, saw 22\\nSkipping line 5012210: expected 15 fields, saw 22\\nSkipping line 5021546: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 5117714: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 5382553: expected 15 fields, saw 22\\nSkipping line 5405521: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 5652268: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 5761025: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 6094502: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 6875074: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "#df1 = pd.read_csv('amazon_reviews_us_Mobile_Electronics_v1_00.tsv',sep=\"\\t\", error_bad_lines=False)\n",
    "# bad lines exist......\n",
    "#data_source = 'amazon_reviews_us_Mobile_Electronics_v1_00.tsv'\n",
    "data_source='amazon_reviews_us_PC_v1_00.tsv.gz'\n",
    "#data_source='amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz'\n",
    "df1 = pd.read_csv(data_source,sep=\"\\t\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA COLUMNS:\n",
    "marketplace       - 2 letter country code of the marketplace where the review was written.  \n",
    "customer_id       - Random identifier that can be used to aggregate reviews written by a single author.  \n",
    "review_id         - The unique ID of the review.  \n",
    "product_id        - The unique Product ID the review pertains to. In the multilingual dataset the reviews\n",
    "                    for the same product in different countries can be grouped by the same product_id.  \n",
    "product_parent    - Random identifier that can be used to aggregate reviews for the same product.  \n",
    "product_title     - Title of the product.  \n",
    "product_category  - Broad product category that can be used to group reviews  \n",
    "                    (also used to group the dataset into coherent parts).  \n",
    "star_rating       - The 1-5 star rating of the review.  \n",
    "helpful_votes     - Number of helpful votes.  \n",
    "total_votes       - Number of total votes the review received.  \n",
    "vine              - Review was written as part of the Vine program.  \n",
    "verified_purchase - The review is on a verified purchase.  \n",
    "review_headline   - The title of the review.  \n",
    "review_body       - The review text.  \n",
    "review_date       - The date the review was written.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the ones not versified and get a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404509"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.loc[df1['verified_purchase']=='Y',['review_id', 'product_id', 'product_title', 'helpful_votes','review_headline', 'review_body']]\n",
    "df1['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of products that are with at least 200 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    404509.000000\n",
       "mean         14.949848\n",
       "std         120.816383\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           6.000000\n",
       "max       20216.000000\n",
       "Name: review_id, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = df1.groupby('product_id').count()\n",
    "count_df = count_df['review_id']\n",
    "\n",
    "count_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = count_df.loc[lambda x: x>=200]\n",
    "count_df = count_df.sort_values(ascending=False)\n",
    "\n",
    "product_list = count_df.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iXCC Multi pack Lightning cable',\n",
       " 'Generic Car Dashboard Video Camera Vehicle Video Accident Recorder (2.0\" 1080P)',\n",
       " 'iXCC Element II Lightning Cable 6ft, iPhone Charger, for iPhone 7 6s 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](White and Black)',\n",
       " 'iXCC Element II Lightning Cable 6ft, iPhone Charger, for iPhone 7 6s 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](White and Black)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[df1['product_id'].isin(product_list)]\n",
    "\n",
    "df1['product_title'][0:4].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on one product. Get the reviews for one product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wall AC Charger USB Sync Data Cable for iPhone 4, 3GS, and iPod'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = df1[df1['product_id']==product_list[1]]#.drop(columns=['review_id','product_title','product_id'])\n",
    "#title_='Yamaha YPG-235 76-Key Portable Grand Piano Premium Pack'\n",
    "#reviews = df1[df1['product_title']==title_]\n",
    "product_title = reviews['product_title'].tolist()[0]\n",
    "product_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews['review_body']\n",
    "\n",
    "\n",
    "reviews = reviews.str.replace('<br />','')\n",
    "\n",
    "def remove_consecutive(text):\n",
    "    one = re.sub(r\"([eoEO])\\1\\1+\",r\"\\1\\1\",text)\n",
    "    return re.sub(r\"([^eoEO])\\1\\1+\",r\"\\1\",one)\n",
    "\n",
    "reviews = pd.Series(list(map(remove_consecutive,reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.str.split(\"[.!?]+\",expand=True).stack().reset_index() # split sentences\n",
    "#remove empty lines\n",
    "reviews['word_count'] = reviews[0].str.split().apply(len)#.strip().apply(len)\n",
    "reviews = reviews.loc[reviews['word_count']>4,[0]]\n",
    "\n",
    "reviews['text'] = reviews[0].str.strip()\n",
    "reviews = reviews.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews.to_csv(r'/mnt/doc/School/USYD/Capstone/workspace/data_testing/output/sub-set/AmazonBasics Wireless Mouse.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of speech tagging\n",
    "reviews['POS'] = reviews['text'].apply(nltk.word_tokenize).apply(nltk.pos_tag)\n",
    "\n",
    "def getMainWords(pos):\n",
    "    result = '';\n",
    "    for x in pos:\n",
    "        if x[1][0:2] in ['NN','VB']:\n",
    "            result= result+x[0]+' '\n",
    "    if len(result)>0:\n",
    "        result= result[0:len(result)-1]\n",
    "    return result\n",
    "\n",
    "reviews['main'] = list(map(getMainWords,reviews['POS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.loc[reviews['main'].apply(len)>0,['text','main']] #filtering out sentences without any nouns or verbs\n",
    "\n",
    "reviews = reviews.reset_index(drop=True)# reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding / Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load google Universal Sentence Encoder\n",
    "module_dir =\"downloads/encoder-DNA\" #\"downloads/encoder\"\n",
    "embed = hub.Module(module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    start_time=time.time()\n",
    "    reviews['sentence_embedding'] = pd.Series(list(session.run(embed(list(reviews['text'])))))\n",
    "    end_time1=time.time()\n",
    "    reviews['words_embedding'] = pd.Series(list(session.run(embed(list(reviews['main'])))))\n",
    "    end_time2=time.time()\n",
    "    print('time1:',(end_time1-start_time),' time2:',(end_time2-end_time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing datasets\n",
    "X1 = np.array(reviews['sentence_embedding'].tolist())\n",
    "X2 = np.array(reviews['words_embedding'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "#km_s = KMeans(n_clusters=10).fit(X1)  \n",
    "\n",
    "#km_w = KMeans(n_clusters=10).fit(X2)\n",
    "\n",
    "db_s = DBSCAN(eps=0.7).fit(X1)\n",
    "\n",
    "db_w = DBSCAN(eps=0.7).fit(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "#reviews['label_km_sentence'] = km_s.labels_.tolist()\n",
    "#reviews['label_km_word'] = km_w.labels_.tolist()\n",
    "\n",
    "labels_s = db_s.labels_.tolist()\n",
    "labels_w = db_w.labels_.tolist()\n",
    "reviews['label_db_sentence'] = labels_s\n",
    "reviews['label_db_word'] = labels_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(labels_s)) - (1 if -1 in labels_s else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(labels_w)) - (1 if -1 in labels_w else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_dir(product_name, method, params):\n",
    "    dir_pre = '/home/betty35/桌面/Capstone/workspace/data_testing/output/'\n",
    "    dir_ = dir_pre+product_name+'/'+method+'/'+params+'/'\n",
    "    return dir_\n",
    "\n",
    "\n",
    "def make_dir(dir_):\n",
    "    if not os.path.exists(dir_):\n",
    "        try:\n",
    "            os.makedirs(dir_)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "def clean_dir(dir_):\n",
    "    for file_ in os.listdir(dir_):\n",
    "        file_dir = os.path.join(dir_, file_dir)\n",
    "        try:\n",
    "            if os.path.isfile(file_dir):\n",
    "                os.unlink(file_dir)\n",
    "            elif os.path.isdir(file_dir): shutil.rmtree(file_dir)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def make_or_clean_dir(dir_):\n",
    "    make_dir(dir_)\n",
    "    clean_dir(dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_s = len(set(labels_s)) - (1 if -1 in labels_s else 0)\n",
    "n_clusters_w = len(set(labels_w)) - (1 if -1 in labels_w else 0)\n",
    "\n",
    "\n",
    "for i in range(0,n_clusters_s):\n",
    "    dir1 = save_results_dir(product_title,'dbscan','0.7/sentence')\n",
    "    make_or_clean_dir(dir1)\n",
    "    temp = reviews.loc[reviews['label_db_sentence']==i,['text']]\n",
    "    file_name = str(i)+'.txt'\n",
    "    np.savetxt(r''+dir1+file_name, temp.values, fmt='%s')\n",
    "\n",
    "\n",
    "#for i in range(0,n_clusters_w):\n",
    " #   dir1 = '/home/betty35/桌面/Capstone/workspace/data_testing/output/dbscan/'\n",
    "  #  temp = reviews.loc[reviews['label_db_word']==i,['text']]\n",
    "   # file_name = 'word/'+str(i)+'.txt'\n",
    "    #np.savetxt(r''+dir1+file_name, temp.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for km\n",
    "\n",
    "for i in range(0,9):\n",
    "    temp = reviews.loc[reviews['label_km_sentence']==i,['text']]\n",
    "    temp2 = reviews.loc[reviews['label_km_word']==i,['text']]\n",
    "    file_name = 'km10/sentence/'+str(i)+'.txt'\n",
    "    file_name2 = 'km10/word/'+str(i)+'.txt'\n",
    "    np.savetxt(r'/home/betty35/桌面/Capstone/workspace/data_testing/output/'+file_name, temp.values, fmt='%s')\n",
    "    np.savetxt(r'/home/betty35/桌面/Capstone/workspace/data_testing/output/'+file_name2, temp2.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
