{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utils\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "### Tensorflow related\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn  #cell that we would use\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the small dataset\n",
    "df = pd.read_csv('output/corpus/processed_2.csv')\n",
    "contents = df.content.tolist()\n",
    "summaries = df.summary.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count lines of contents: 134982\n",
      "count lines of summaries: 134982\n"
     ]
    }
   ],
   "source": [
    "print('count lines of contents:', len(contents))\n",
    "print('count lines of summaries:', len(summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = contents + summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alone take one either sit brc wife took instructor get take msf pivotal beneficial brc experience wife instructors couple good ol boys earning little extra cash weekends believe many new riders put much stock msf course instructor say though end motorcycling technique curriculum essentially defensive driving techniques taught high school drivers ed magic bean keeps dying street magic common sense pill either class geared toward cruiser riders well myths front brake vs rear brake actually taught class husband difficult refute misinformation given motorcycling god placed fate edit would like add 6 miles 2nd ride went wide right hander froze controls crashed grass behind watch hear chatterboxes whole thing uninjured baby ninja rideable week passed brc instructors said top class'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed corpus: line 0 --- ['<GO>', 'alone', 'take', 'one', 'either', 'sit', 'brc', 'wife', 'took', 'instructor', 'get', 'take', 'msf', 'pivotal', 'beneficial', 'brc', 'experience', 'wife', 'instructors', 'couple', 'good', 'ol', 'boys', 'earning', 'little', 'extra', 'cash', 'weekends', 'believe', 'many', 'new', 'riders', 'put', 'much', 'stock', 'msf', 'course', 'instructor', 'say', 'though', 'end', 'motorcycling', 'technique', 'curriculum', 'essentially', 'defensive', 'driving', 'techniques', 'taught', 'high', 'school', 'drivers', 'ed', 'magic', 'bean', 'keeps', 'dying', 'street', 'magic', 'common', 'sense', 'pill', 'either', 'class', 'geared', 'toward', 'cruiser', 'riders', 'well', 'myths', 'front', 'brake', 'vs', 'rear', 'brake', 'actually', 'taught', 'class', 'husband', 'difficult', 'refute', 'misinformation', 'given', 'motorcycling', 'god', 'placed', 'fate', 'edit', 'would', 'like', 'add', '6', 'miles', '2nd', 'ride', 'went', 'wide', 'right', 'hander', 'froze', 'controls', 'crashed', 'grass', 'behind', 'watch', 'hear', 'chatterboxes', 'whole', 'thing', 'uninjured', 'baby', 'ninja', 'rideable', 'week', 'passed', 'brc', 'instructors', 'said', 'top', 'class', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "processed_corpus = []\n",
    "for line in corpus:\n",
    "    line = tl.nlp.process_sentence(line, start_word=\"<GO>\", end_word=\"<EOS>\")\n",
    "    processed_corpus.append(line)\n",
    "\n",
    "print('processed corpus: line 0 ---',processed_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### load numberbatch word-embedding\n",
    "embeddings_index = {}\n",
    "with open('downloads/embedding/numberbatch-en.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Count words (Just for test)\n",
    "def count_words(count_dict, text):\n",
    "    '''Count the number of occurrences of each word in a set of text'''\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = {}\n",
    "\n",
    "count_words(word_counts, summaries)\n",
    "count_words(word_counts, contents)\n",
    "            \n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of words that are missing from CN, and are used more than our threshold.\n",
    "missing_words = 0\n",
    "missing_word_list=[]\n",
    "threshold = 20\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            missing_word_list.append(word)\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from CN:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Creating vocabulary.\n",
      "[TL]     Total words: 259872\n",
      "[TL]     Words in vocabulary: 87760\n",
      "[TL]     Wrote vocabulary file: output/corpus/vocab.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.nlp.SimpleVocabulary at 0x19ee65d5f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.nlp.create_vocab(processed_corpus, word_counts_output_file='output/corpus/vocab.txt', min_word_count=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Initializing vocabulary from file: output/corpus/vocab.txt\n",
      "[TL] Vocabulary from output/corpus/vocab.txt : <GO> <EOS> <UNK>\n",
      "[TL]     vocabulary with 87761 words (includes start_word, end_word, unk_word)\n",
      "[TL]       start_id: 1\n",
      "[TL]       end_id  : 2\n",
      "[TL]       unk_id  : 87760\n",
      "[TL]       pad_id  : 0\n"
     ]
    }
   ],
   "source": [
    "vocab = tl.nlp.Vocabulary('output/corpus/vocab.txt', start_word=\"<GO>\", end_word=\"<EOS>\", unk_word=\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <GO> <EOS> . , the would to like\n"
     ]
    }
   ],
   "source": [
    "print(vocab.id_to_word(0),vocab.id_to_word(1),vocab.id_to_word(2),\n",
    "      vocab.id_to_word(3),vocab.id_to_word(4),vocab.id_to_word(5),\n",
    "      vocab.id_to_word(6),vocab.id_to_word(7),vocab.id_to_word(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87760"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word_to_id('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<UNK>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.id_to_word(87760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ints(text, word_count, unk_count, eos=False):\n",
    "    '''Convert words in text to an integer.\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for sentence in text:\n",
    "        sentence_ints = []\n",
    "        for word in sentence.split():\n",
    "            word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                sentence_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                unk_count += 1\n",
    "        if eos:\n",
    "            sentence_ints.append(vocab_to_int[\"<S/>\"])\n",
    "        ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
